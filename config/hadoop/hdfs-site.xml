<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?><!--
LicensedundertheApacheLicense,Version2.0(the"License");
youmaynotusethisfileexceptincompliancewiththeLicense.
YoumayobtainacopyoftheLicenseat

http://www.apache.org/licenses/LICENSE-2.0

Unlessrequiredbyapplicablelaworagreedtoinwriting,software
distributedundertheLicenseisdistributedonan"ASIS"BASIS,
WITHOUTWARRANTIESORCONDITIONSOFANYKIND,eitherexpressorimplied.
See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--><!-- Put site-specific property overrides in this file. --><configuration>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///hadoop/data/namenode/name,/hadoop1/data/namenode/name</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir.restore</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///hadoop/data/hdfs,/hadoop1/data/hdfs,/hadoop2/data/hdfs,/hadoop3/data/hdfs,/hadoop4/data/hdfs,/hadoop5/data/hdfs,/hadoop6/data/hdfs,/hadoop7/data/hdfs,/hadoop8/data/hdfs,/hadoop9/data/hdfs,/hadoop10/data/hdfs,/hadoop11/data/hdfs</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.blocksize</name>
        <value>134217728</value>
    </property>
    <property>
        <name>dfs.namenode.handler.count</name>
        <value>200</value>
    </property>
    <property>
        <name>dfs.namenode.service.handler.count</name>
        <value>200</value>
    </property>
    <property>
        <name>dfs.qjournal.write-txns.timeout.ms</name>
        <value>60000</value>
    </property>
    <property>
        <name>dfs.blockreport.incremental.intervalMsec</name>
        <value>300</value>
    </property>
    <property>
        <name>dfs.namenode.replication.interval</name>
        <value>10</value>
    </property>
    <!--全量块汇报，默认6小时，更改12小时-->
    <property>
        <name>dfs.blockreport.intervalMsec</name>
        <value>43200000</value>
    </property>
    <property>
        <name>dfs.datanode.du.reserved</name>
        <value>5242880</value>
    </property>
    <property>
        <name>dfs.support.append</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
    </property>

    <property>
        <name>dfs.nameservices</name>
        <value>mobPrdCluster01,mobPrdCluster02,mobPrdCluster03</value>
    </property>
    <property>
        <name>dfs.ha.namenodes.mobPrdCluster01</name>
        <value>nn1,nn2</value>
    </property>
    <property>
        <name>dfs.ha.namenodes.mobPrdCluster02</name>
        <value>nn3,nn4</value>
    </property>
    <property>
        <name>dfs.ha.namenodes.mobPrdCluster03</name>
        <value>nn5,nn6</value>
    </property>
    <!-- set the full address and IPC port of the NameNode processs -->
    <property>
        <name>dfs.namenode.rpc-address.mobPrdCluster01.nn1</name>
        <value>10-90-49-222-jhdxyjd.mob.local:8020</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.mobPrdCluster01.nn1</name>
        <value>10-90-49-222-jhdxyjd.mob.local:8040</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.mobPrdCluster01.nn2</name>
        <value>10-90-49-226-jhdxyjd.mob.local:8020</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.mobPrdCluster01.nn2</name>
        <value>10-90-49-226-jhdxyjd.mob.local:8040</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.mobPrdCluster02.nn3</name>
        <value>10-90-49-223-jhdxyjd.mob.local:8020</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.mobPrdCluster02.nn3</name>
        <value>10-90-49-223-jhdxyjd.mob.local:8040</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.mobPrdCluster02.nn4</name>
        <value>10-90-49-224-jhdxyjd.mob.local:8020</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.mobPrdCluster02.nn4</name>
        <value>10-90-49-224-jhdxyjd.mob.local:8040</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.mobPrdCluster03.nn5</name>
        <value>10-90-49-225-jhdxyjd.mob.local:8020</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.mobPrdCluster03.nn5</name>
        <value>10-90-49-225-jhdxyjd.mob.local:8040</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.mobPrdCluster03.nn6</name>
        <value>10-90-49-227-jhdxyjd.mob.local:8020</value>
    </property>
    <property>
        <name>dfs.namenode.servicerpc-address.mobPrdCluster03.nn6</name>
        <value>10-90-49-227-jhdxyjd.mob.local:8040</value>
    </property>
    <!-- set the addresses for both NameNodes’ HTTP servers to listen on -->
    <property>
        <name>dfs.namenode.http-address.mobPrdCluster01.nn1</name>
        <value>10-90-49-222-jhdxyjd.mob.local:9870</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.mobPrdCluster01.nn2</name>
        <value>10-90-49-226-jhdxyjd.mob.local:9870</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.mobPrdCluster02.nn3</name>
        <value>10-90-49-223-jhdxyjd.mob.local:9870</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.mobPrdCluster02.nn4</name>
        <value>10-90-49-224-jhdxyjd.mob.local:9870</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.mobPrdCluster03.nn5</name>
        <value>10-90-49-225-jhdxyjd.mob.local:9870</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.mobPrdCluster03.nn6</name>
        <value>10-90-49-227-jhdxyjd.mob.local:9870</value>
    </property> 


    <!--  identifies the group of JNs where the NameNodes will write/read edits -->
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://10-90-49-222-jhdxyjd.mob.local:8485;10-90-49-223-jhdxyjd.mob.local:8485;10-90-49-224-jhdxyjd.mob.local:8485;10-90-49-225-jhdxyjd.mob.local:8485;10-90-49-226-jhdxyjd.mob.local:8485/mobPrdCluster01</value>
    </property>

    <!--
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://10-90-49-222-jhdxyjd.mob.local:8485;10-90-49-223-jhdxyjd.mob.local:8485;10-90-49-224-jhdxyjd.mob.local:8485;10-90-49-225-jhdxyjd.mob.local:8485;10-90-49-226-jhdxyjd.mob.local:8485/mobPrdCluster02</value>
    </property>
    -->

    <!--
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://10-90-49-222-jhdxyjd.mob.local:8485;10-90-49-223-jhdxyjd.mob.local:8485;10-90-49-224-jhdxyjd.mob.local:8485;10-90-49-225-jhdxyjd.mob.local:8485;10-90-49-226-jhdxyjd.mob.local:8485/mobPrdCluster03</value>
    </property>
    -->

    <property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/var/soft/data/journal/</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.mobPrdCluster01</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.mobPrdCluster02</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.mobPrdCluster03</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>

    <!--datanode间进行block数据传输的最大线程数 -->
    <property>
        <name>dfs.datanode.max.transfer.threads</name>
        <value>8192</value>
    </property>
    <!--默认10 RPC处理线程数 -->
    <property>
        <name>dfs.datanode.handler.count</name>
        <value>50</value>
    </property>
    <!--表示datanode节点，磁盘允许错误数量 -->
    <property>
        <name>dfs.datanode.failed.volumes.tolerated</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.datanode.socket.write.timeout</name>
        <value>960000</value>
    </property>
    <property>
        <name>dfs.disk.balancer.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.disk.balancer.max.disk.throughputInMBperSec</name>
        <value>50</value>
    </property>
    <property>
        <name>dfs.disk.balancer.block.tolerance.percent</name>
        <value>10</value>
    </property>

    <property>
        <name>dfs.permissions.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.image.parallel.load</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.permissions.superusergroup</name>
        <value>hadoop</value>
    </property>
    <property>
        <name>dfs.namenode.datanode.registration.ip-hostname-check</name>
        <value>false</value>
    </property>
    <property>
        <name>dfs.datanode.balance.bandwidthPerSec</name>
        <value>100m</value>
    </property>
    <property>
        <name>dfs.datanode.balance.max.concurrent.moves</name>
        <value>100</value>
    </property>
    <property>
        <name>dfs.namenode.acls.enabled</name>
        <value>true</value>
    </property>
    <property>
        <name>hadoop.security.impersonation.provider.class</name>
        <value>org.apache.hadoop.security.authorize.my.MyDefaultImpersonationProvider</value>
    </property>
    <property>
        <name>dfs.namenode.audit.log.async</name>
        <value>true</value>
    </property>
   
    <property>
        <name>dfs.namenode.avoid.read.stale.datanode</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.namenode.avoid.write.stale.datanode</name>
        <value>true</value>
    </property>    

    <property>
        <name>dfs.permissions</name>
        <value>true</value>
    </property>
    <property>
        <name>dfs.namenode.inode.attributes.provider.class</name>
        <value>org.apache.ranger.authorization.hadoop.RangerHdfsAuthorizer</value>
    </property>
    <property>
        <name>dfs.permissions.ContentSummary.subAccess</name>
        <value>true</value>
    </property>
</configuration>
